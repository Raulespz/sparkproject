{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ed00e1",
   "metadata": {},
   "source": [
    "# Batch  processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea78df3a",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "192f53bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "PySparkRuntimeError",
     "evalue": "[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPySparkRuntimeError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m----> 8\u001b[0m sc \u001b[38;5;241m=\u001b[39m pyspark\u001b[38;5;241m.\u001b[39mSparkContext(appName\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSPARK_API\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession(sc)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 201\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[0;32m    204\u001b[0m         master,\n\u001b[0;32m    205\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[0;32m    216\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\context.py:436\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[1;32m--> 436\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m launch_gateway(conf)\n\u001b[0;32m    437\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\java_gateway.py:107\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkRuntimeError(\n\u001b[0;32m    108\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJAVA_GATEWAY_EXITED\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    109\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    110\u001b[0m     )\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(conn_info_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m info:\n\u001b[0;32m    113\u001b[0m     gateway_port \u001b[38;5;241m=\u001b[39m read_int(info)\n",
      "\u001b[1;31mPySparkRuntimeError\u001b[0m: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number."
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"SPARK_API\")\n",
    "spark = SparkSession(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880ffb6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Number of passengers in each class in the Titanic dataset:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m count\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferSchema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m passengerCounts \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39magg(count(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      9\u001b[0m passengerCounts\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# Number of passengers in each class in the Titanic dataset:\n",
    "\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"titanic.csv\")\n",
    "\n",
    "passengerCounts = df.groupBy(\"Pclass\").agg(count(\"*\").alias(\"count\"))\n",
    "\n",
    "passengerCounts.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819855a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Determine the number of passengers by age group (e.g. 0-10 years, 11-20 years, etc.) and by class:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m count, when\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferSchema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m ageRanges \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m), (\u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m20\u001b[39m), (\u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m30\u001b[39m), (\u001b[38;5;241m31\u001b[39m, \u001b[38;5;241m40\u001b[39m), (\u001b[38;5;241m41\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m51\u001b[39m, \u001b[38;5;241m60\u001b[39m), (\u001b[38;5;241m61\u001b[39m, \u001b[38;5;241m70\u001b[39m), (\u001b[38;5;241m71\u001b[39m, \u001b[38;5;241m80\u001b[39m)]\n\u001b[0;32m      9\u001b[0m ageRangesDf \u001b[38;5;241m=\u001b[39m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# Determine the number of passengers by age group (e.g. 0-10 years, 11-20 years, etc.) and by class:\n",
    "\n",
    "from pyspark.sql.functions import count, when\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"titanic.csv\")\n",
    "\n",
    "ageRanges = [(0, 10), (11, 20), (21, 30), (31, 40), (41, 50), (51, 60), (61, 70), (71, 80)]\n",
    "\n",
    "ageRangesDf = df\n",
    "for lower, upper in ageRanges:\n",
    "    ageRangesDf = ageRangesDf.withColumn(f\"AgeRange_{lower}_to_{upper}\", when(df.Age.between(lower, upper), 1).otherwise(0))\n",
    "\n",
    "passengerCountsByAge = ageRangesDf.groupBy(\"Pclass\") \\\n",
    "                                 .agg(count(when(ageRangesDf.AgeRange_0_to_10 == 1, True)).alias(\"0-10\"),\n",
    "                                      count(when(ageRangesDf.AgeRange_11_to_20 == 1, True)).alias(\"11-20\"),\n",
    "                                      count(when(ageRangesDf.AgeRange_21_to_30 == 1, True)).alias(\"21-30\"),\n",
    "                                      count(when(ageRangesDf.AgeRange_31_to_40 == 1, True)).alias(\"31-40\"),\n",
    "                                      count(when(ageRangesDf.AgeRange_41_to_50 == 1, True)).alias(\"41-50\"),\n",
    "                                      count(when(ageRangesDf.AgeRange_51_to_60 == 1, True)).alias(\"51-60\"),\n",
    "                                      count(when(ageRangesDf.AgeRange_61_to_70 == 1, True)).alias(\"61-70\"),\n",
    "                                      count(when(ageRangesDf.AgeRange_71_to_80 == 1, True)).alias(\"71-80\"))\n",
    "\n",
    "passengerCountsByAge.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a42398",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Number of passengers by gender in each class\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m count\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferSchema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m passengerCountsBySex \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39magg(count(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      9\u001b[0m passengerCountsBySex\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# Number of passengers by gender in each class\n",
    "\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"titanic.csv\")\n",
    "\n",
    "passengerCountsBySex = df.groupBy(\"Pclass\", \"Sex\").agg(count(\"*\").alias(\"count\"))\n",
    "\n",
    "passengerCountsBySex.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5def8f44",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Determining the number of passengers between survivors and non-survivors\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m count\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferSchema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m survivorsCounts \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39magg(count(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      9\u001b[0m survivorsCounts\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# Determining the number of passengers between survivors and non-survivors\n",
    "\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"titanic.csv\")\n",
    "\n",
    "survivorsCounts = df.groupBy(\"Survived\").agg(count(\"*\").alias(\"count\"))\n",
    "\n",
    "survivorsCounts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02fcc491",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Average age of passengers by gender and by class:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m avg\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferSchema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m avgAgeBySexAndClass \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39magg(avg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_age\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      9\u001b[0m avgAgeBySexAndClass\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# Average age of passengers by gender and by class:\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"titanic.csv\")\n",
    "\n",
    "avgAgeBySexAndClass = df.groupBy(\"Pclass\", \"Sex\").agg(avg(\"Age\").alias(\"avg_age\"))\n",
    "\n",
    "avgAgeBySexAndClass.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a30ad964",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Average age of passengers by survival\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m avg\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferSchema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m avgAgeBySurvival \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39magg(avg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_age\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      9\u001b[0m avgAgeBySurvival\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# Average age of passengers by survival\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"titanic.csv\")\n",
    "\n",
    "avgAgeBySurvival = df.groupBy(\"Survived\").agg(avg(\"Age\").alias(\"avg_age\"))\n",
    "\n",
    "avgAgeBySurvival.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "214224dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Average age of first class passengers\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m avg\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferSchema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m avgAgeFirstClass \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfilter(df\u001b[38;5;241m.\u001b[39mPclass \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39magg(avg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_age\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      9\u001b[0m avgAgeFirstClass\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# Average age of first class passengers\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"titanic.csv\")\n",
    "\n",
    "avgAgeFirstClass = df.filter(df.Pclass == 1).agg(avg(\"Age\").alias(\"avg_age\"))\n",
    "\n",
    "avgAgeFirstClass.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1b4e116",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Average age of passengers by class and survival status\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m avg\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferSchema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m avgAgeByClassAndSurvival \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39magg(avg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_age\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      9\u001b[0m avgAgeByClassAndSurvival\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# Average age of passengers by class and survival status\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"titanic.csv\")\n",
    "\n",
    "avgAgeByClassAndSurvival = df.groupBy(\"Pclass\", \"Survived\").agg(avg(\"Age\").alias(\"avg_age\"))\n",
    "\n",
    "avgAgeByClassAndSurvival.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba2275",
   "metadata": {},
   "source": [
    "## Exercises to solve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca3fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the age of the oldest and youngest passengers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573a993",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "+--------+--------+  \n",
    "|min(Age)|max(Age)|  \n",
    "+--------+--------+  \n",
    "|    0.42|    80.0|  \n",
    "+--------+--------+    \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b4c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the number of women and men aged 30 and over in first class\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb78645",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "First class, number of women over 30: 50\n",
    "First class, age 30 and over: 75\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f381f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passenger survival rates by cabin.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc4b336",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "+-------+------------------+\n",
    "|  Cabin|      SurvivalRate|\n",
    "+-------+------------------+\n",
    "|    A23|               1.0|\n",
    "|    B79|               1.0|\n",
    "|    E44|               0.5|\n",
    "|  F E69|               1.0|\n",
    "|    D28|               1.0|\n",
    "|    C78|               0.5|\n",
    "|    C95|               0.0|\n",
    "|  F G73|               0.0|\n",
    "|B58 B60|               0.5|\n",
    "|     D7|               1.0|\n",
    "|   C128|               0.0|\n",
    "|    B39|               1.0|\n",
    "|    B22|               0.5|\n",
    "|   C110|               0.0|\n",
    "|    D21|               1.0|\n",
    "|     F2|0.6666666666666666|\n",
    "|    B30|               0.0|\n",
    "|   C104|               1.0|\n",
    "|    B50|               1.0|\n",
    "|     A6|               1.0|\n",
    "+-------+------------------+\n",
    "only showing top 20 rows\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passenger survival based on the place of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4e022a",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "+--------+-------------------+\n",
    "|Embarked|       SurvivalRate|\n",
    "+--------+-------------------+\n",
    "|       Q|0.38961038961038963|\n",
    "|    null|                1.0|\n",
    "|       C| 0.5535714285714286|\n",
    "|       S|0.33695652173913043|\n",
    "+--------+-------------------+\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa08edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most common age group among passengers is 10 years.Scroll down. 0, 10, 20, etc..\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e005b",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "+-----------+-----+\n",
    "|Age_rounded|count|\n",
    "+-----------+-----+\n",
    "|       30.0|  201|\n",
    "|       20.0|  200|\n",
    "|       40.0|  120|\n",
    "|       50.0|   73|\n",
    "|        0.0|   40|\n",
    "|       10.0|   38|\n",
    "|       60.0|   31|\n",
    "|       70.0|   10|\n",
    "|       80.0|    1|\n",
    "|       null|    0|\n",
    "+-----------+-----+\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b379067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The survival rate of passengers in the most common age group.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26daae",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "+-----------+-----+-------------------+\n",
    "|Age_rounded|count|        AvgSurvived|\n",
    "+-----------+-----+-------------------+\n",
    "|       30.0|  201| 0.3880597014925373|\n",
    "|       20.0|  200|              0.365|\n",
    "|       40.0|  120|              0.425|\n",
    "|       50.0|   73|  0.410958904109589|\n",
    "|        0.0|   40|              0.675|\n",
    "|       10.0|   38|0.47368421052631576|\n",
    "|       60.0|   31| 0.3870967741935484|\n",
    "|       70.0|   10|                0.0|\n",
    "|       80.0|    1|                1.0|\n",
    "|       null|    0| 0.2937853107344633|\n",
    "+-----------+-----+-------------------+\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average age and class of passengers by survival.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea034f2",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "+--------+------------------+------------------+\n",
    "|Survived|          avg(Age)|       avg(Pclass)|\n",
    "+--------+------------------+------------------+\n",
    "|       1|28.343689655172415|1.9502923976608186|\n",
    "|       0| 30.62617924528302|2.5318761384335153|\n",
    "+--------+------------------+------------------+\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of passengers, by class and gender.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d8a6c8",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "+------+------+------------------+\n",
    "|Pclass|   Sex|count(PassengerId)|\n",
    "+------+------+------------------+\n",
    "|     2|female|                76|\n",
    "|     3|  male|               347|\n",
    "|     1|  male|               122|\n",
    "|     3|female|               144|\n",
    "|     1|female|                94|\n",
    "|     2|  male|               108|\n",
    "+------+------+------------------+\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the survival rate among passengers whose cabin brain age is unknown.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6fbf0a",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "+-------------------+\n",
    "|      avg(Survived)|\n",
    "+-------------------+\n",
    "|0.29985443959243085|\n",
    "+-------------------+\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ffc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of passengers with no known cabin, by class and survival status.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fe0df4",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "+------+--------+------------------+\n",
    "|PClass|Survived|count(PassengerId)|\n",
    "+------+--------+------------------+\n",
    "|     1|       0|                21|\n",
    "|     3|       1|               113|\n",
    "|     1|       1|                19|\n",
    "|     2|       1|                74|\n",
    "|     2|       0|                94|\n",
    "|     3|       0|               366|\n",
    "+------+--------+------------------+\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
